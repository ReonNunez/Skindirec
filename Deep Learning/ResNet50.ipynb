{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **LIBRARY IMPORT**","metadata":{"id":"zGcIr20RXQto","papermill":{"duration":0.018768,"end_time":"2021-11-23T03:40:28.595526","exception":false,"start_time":"2021-11-23T03:40:28.576758","status":"completed"},"tags":[]}},{"cell_type":"code","source":"### Imports\n\nimport numpy as np #used for working with arrays\nimport cv2 as cv\nimport random #generate random numbers\nimport pickle\nimport glob # used to retrieve files/pathnames matching a specified pattern\nimport os #operating system\nimport shutil #high-level operation on a file like a copy, create, and remote operation on the file.\nimport tensorflow as tf\nimport tensorflow.keras as keras #for deep learning\nimport matplotlib.pyplot as plt #for plotting functions\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Dropout,AveragePooling2D, Flatten #for classification layer\nfrom sklearn.model_selection import train_test_split  #for splitting data\n!pip install livelossplot #live plotting of loss and accuracy graph\nfrom livelossplot.keras import PlotLossesCallback\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\n","metadata":{"papermill":{"duration":14.656127,"end_time":"2021-11-23T03:40:43.266246","exception":false,"start_time":"2021-11-23T03:40:28.610119","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TRAINING PARAMETERS**","metadata":{"id":"CFQw40aeXFMD","papermill":{"duration":0.01063,"end_time":"2021-11-23T03:40:43.28829","exception":false,"start_time":"2021-11-23T03:40:43.27766","status":"completed"},"tags":[]}},{"cell_type":"code","source":"selectedModel = \"resnet50\";\nneurons = [4096,0.8,1024, 256]\ndataPath = '../input/traindata/' ## Folder for dataset\n\next = [\".jpg\",\".JPG\",\".jpeg\",\".JPEG\",\".png\",\".PNG\"]\nlearningRate = 0.00001; #hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated\ntest_split_size=0.20\nvalidation_split_size=0;\nmaxEpochs = 500; \nuseAllSamples = True ## True to Consume All Traindata per Epoch (for feature crucial classification like defects)\nbatchSize = 16 # number of training samples to work through before the model's internal parameters are updated.\nfixedStepSize = 2 ## If useAllSamples is False, get no. steps per epoch7\nenableEarlyStop = True; #stop training once the model performance stops improving on a hold out validation dataset\nestype = \"accuracy\"\npatience = 5\nlayersToUnfreeze = 0\n\n## Data Augment Parameters\nrotAngle = 0\nflipHorizontal = False\nflipVertical = False\n\n\nimport os\nfor root, dirs, files in os.walk(dataPath):\n    break;\n\nnumClasses = len(dirs);\n\n\n","metadata":{"id":"V-tntAvGdZXT","papermill":{"duration":0.030916,"end_time":"2021-11-23T03:40:43.330213","exception":false,"start_time":"2021-11-23T03:40:43.299297","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL TRAINER**","metadata":{"id":"lglPl7m0ZKxL","papermill":{"duration":0.011061,"end_time":"2021-11-23T03:40:44.889644","exception":false,"start_time":"2021-11-23T03:40:44.878583","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#from tensorflow.keras.preprocessing import image\nif selectedModel == \"vgg16\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.vgg16 import preprocess_input\n    sourceModel = keras.applications.VGG16\nelif selectedModel == \"inceptionv3\":\n    imgsz = 299; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.inception_v3 import preprocess_input\n    sourceModel = keras.applications.InceptionV3\nelif selectedModel == \"resnet50\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.resnet50 import preprocess_input\n    sourceModel = keras.applications.ResNet50\n\n\n    \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\n# Adam is an optimization algorithm, replacing the very old Gradient Descent.\n\n\nmodelName = 'model_' + selectedModel + '.model';\n\n\n#imports the model and discards the classification layer.\nbase_model=sourceModel(weights='imagenet', \\\n                          include_top=False, \\\n                          input_shape = (imgsz,imgsz,3)); \n\n\n#Show Architecture\nfor i,layer in enumerate(base_model.layers):\n    print(i,layer.name,layer.trainable)\n    \n\n## To Check Last Layer\n#base_model.layers[-1]\n\n\nx=base_model.output\n\naddedLayers = 0;\n# if selectedModel == \"vgg16\":\n\nx = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n\nfor neuron in neurons:\n  if neuron<1:\n    x=Dropout(neuron)(x)\n  else:\n    x=Dense(neuron,activation='relu')(x) \n  addedLayers = addedLayers + 1\n\npreds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n\n# elif selectedModel == \"inceptionv3\":\n#     x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n#     preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n# elif selectedModel == \"resnet50\":  \n#x = GlobalAveragePooling2D()(x); addedLayers = addedLayers + 1;\n#preds=Dense(numClasses,activation='softmax')(x); addedLayers = addedLayers + 1;\n\n    \n\n\nmodel=Model(inputs=base_model.input,outputs=preds)\n\n                  \n              \nfor layer in model.layers[0:-(addedLayers+layersToUnfreeze)]:\n    layer.trainable = False\n\n#Show Architecture\nfor i,layer in enumerate(model.layers):\n    print(i,layer.name,layer.trainable)\n\n    \n## This datagen is used only for viewing, prior to preprocessing\nviewing_datagent=ImageDataGenerator(rotation_range=rotAngle,\n                                horizontal_flip=flipHorizontal,\n                                vertical_flip=flipVertical,\n                                validation_split=validation_split_size)\n\n## Official Training Datagen, PreProcessed\nif rotAngle == 0:\n    train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n                                    #horizontal_flip=flipHorizontal,\n                                    #vertical_flip=flipVertical,\n                                    #validation_split=validation_split_size) \nelse:\n    train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n                                    #rotation_range=rotAngle,\n                                    #horizontal_flip=flipHorizontal,\n                                    #vertical_flip=flipVertical,\n                                    #validation_split=validation_split_size) \n\nprint(\"Training Dataset:\");\ntrain_generator=train_datagen.flow_from_directory(dataPath,\n                                                target_size=(imgsz,imgsz),\n                                                color_mode='rgb',\n                                                batch_size=batchSize,\n                                                class_mode='categorical',\n                                                shuffle=False,\n                                                subset='training');\n\"\"\"\"\nprint(\"Test Validation Dataset:\");\nvalidation_generator=train_datagen.flow_from_directory(dataPath,\n                                                target_size=(imgsz,imgsz),\n                                                color_mode='rgb',\n                                                batch_size=batchSize,\n                                                class_mode='categorical',\n                                                subset='validation',\n                                                shuffle=False);\"\"\"\n\nprint(\"Sample Viewing Dataset:\");\n## Only for Viewing Unprocessed Images\nview_generator=viewing_datagent.flow_from_directory(dataPath,\n                                                target_size=(imgsz,imgsz),\n                                                color_mode='rgb',\n                                                batch_size=batchSize,\n                                                class_mode='categorical',\n                                                shuffle=False);\n\n## Show 5 Sample Images\nx,y = view_generator.next() #returns the next item\nfor i in range(0,min([batchSize,5])):\n    img = x[i]\n    plt.imshow(img.astype(np.uint8))\n    plt.show()\n    \n                                                  \n\nadamopt = optimizers.Adam(lr=learningRate);\nmodel.compile(optimizer=adamopt, \\\n              loss='categorical_crossentropy', \\\n              metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be validation accuracy\n\nif useAllSamples:\n   step_size_train=train_generator.n//train_generator.batch_size\nelse:\n    step_size_train=fixedStepSize\n\nif enableEarlyStop:\n    es = EarlyStopping(monitor=estype,mode='auto', patience=patience)\n    \n    history = model.fit_generator(generator=train_generator,\n                      steps_per_epoch=step_size_train,\n                      epochs=maxEpochs,\n                      callbacks=[PlotLossesCallback(),es]);\nelse:\n    \n    history = model.fit_generator(generator=train_generator,\n                      steps_per_epoch=step_size_train,\n                      epochs=maxEpochs);\n\n\n\n\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\n#plt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n\n### Save Model\ntf.keras.models.save_model(\n    model,\n    modelName,\n    overwrite=True,\n    include_optimizer=True\n)\nmodel.save(\"resnet50_novali.h5\")\n#### Save Label Names\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nprint(labels);\n\nfid = open('label_' + selectedModel + '.sav','wb');\npickle.dump(labels, fid);\nfid.close();\n\n\nprint(\"Model successfully trained and saved.\");\n","metadata":{"id":"_4KaQfSacvJK","outputId":"9b7b2dcf-3744-4aa3-bbb4-6040fbc214cf","papermill":{"duration":2972.049124,"end_time":"2021-11-23T04:30:16.949977","exception":false,"start_time":"2021-11-23T03:40:44.900853","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training Accuracy of the model is - \" , model.evaluate(train_generator)[1]*100 , \"%\")\n#print(\"Validation Accuracy of the model is - \" , model.evaluate(validation_generator)[1]*100 , \"%\")","metadata":{"id":"vqSHIvoq8Kul","papermill":{"duration":149.079949,"end_time":"2021-11-23T04:32:46.045835","exception":false,"start_time":"2021-11-23T04:30:16.965886","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL TESTING**","metadata":{"id":"1RfmtW9mV0OA","papermill":{"duration":0.331241,"end_time":"2021-11-23T04:32:46.878151","exception":false,"start_time":"2021-11-23T04:32:46.54691","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#from tensorflow.keras.preprocessing import image\nif selectedModel == \"vgg16\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.vgg16 import preprocess_input\n    sourceModel = keras.applications.VGG16\nelif selectedModel == \"inceptionv3\":\n    imgsz = 299; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.inception_v3 import preprocess_input\n    sourceModel = keras.applications.InceptionV3\nelif selectedModel == \"resnet50\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.resnet50 import preprocess_input\n    sourceModel = keras.applications.ResNet50\n\n\nmodelName = \"model_\" + selectedModel + \".model\";\n\n\ntestmodel = tf.keras.models.load_model(\"resnet50_novali.h5\")\n#    custom_objects=None,\n#    compile=True\n#)\n\nf = open(\"label_\" + selectedModel + \".sav\",'rb');labels = pickle.load(f);f.close();\nlabels = list(labels.values());\n\nX = [];\ny = [];\n\n\nfor label in labels:\n\n    fileList = []\n    for ctrext in range(0,len(ext)):\n        \n        fileList.extend(glob.glob(dataPath[:-1] + \"test\" + \"/\" + label + \"/*\" + ext[ctrext]))\n    \n    \n    \n    for thisFile in fileList:\n        \n\n        ## CV IMAGE LOAD\n        img = cv.imread(thisFile);\n        img = cv.cvtColor(img,cv.COLOR_BGR2RGB);\n        \n      \n        img = cv.resize(img,(imgsz,imgsz));\n        \n        \n        img = preprocess_input(img);\n        \n        X.append(img);\n        y.append(labels.index(label));\n        \n    \n\ny_preds = testmodel.predict(np.array(X));\ny_pred = [];\nfor y_preds_i in y_preds:\n    y_pred.append(np.argmax(y_preds_i));\n#y_pred = testmodel.predict(X);\n\naccuracy = sum(np.equal(y_pred,y)) / len(y) * 100\n\nconfmat = confusion_matrix(y, y_pred)\ndisp=ConfusionMatrixDisplay(confusion_matrix=confmat, display_labels=labels)\n\ndisp.plot(xticks_rotation='vertical',values_format='')\nplt.show()\n\n\n\nprint()\nprint(\"RANK 1 Accuracy Against Test Data: \" + \"{:.2f}\".format(accuracy) + \" %\");\n\n\n\n\nprint()\nprint('CONFUSION MATRIX:')\nprint(confmat)\n\nprint(labels);\n\nprint();\nprint(\"CLASSIFICATION REPORT:\")\nprint(classification_report(y, y_pred))\n\n\n\n\n\n## SHOW OUTPUT BREAKDOWN\nprint()\nprint(\"OUTPUT DISTRIBUTION:\")\noutctr = 0;\ntotal = sum(sum(confmat));\nfor col in confmat.T:\n    \n    totalcol = sum(col)\n    \n    print(labels[outctr] + \": \" + (\"%1.2f\") % ((totalcol / total) * 100) + \"%\")\n    \n    outctr = outctr + 1;\n","metadata":{"id":"XGfGhb_wVxGr","outputId":"763bdd35-6812-46f0-8b87-8d578d9c9e16","papermill":{"duration":14.764486,"end_time":"2021-11-23T04:33:02.511606","exception":false,"start_time":"2021-11-23T04:32:47.74712","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **TEST ONE**","metadata":{"id":"Mzy50TCWWCXw","papermill":{"duration":0.285381,"end_time":"2021-11-23T04:33:03.08552","exception":false,"start_time":"2021-11-23T04:33:02.800139","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n#from tensorflow.keras.preprocessing import image\nif selectedModel == \"vgg16\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.vgg16 import preprocess_input\n    sourceModel = keras.applications.VGG16\nelif selectedModel == \"inceptionv3\":\n    imgsz = 299; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.inception_v3 import preprocess_input\n    sourceModel = keras.applications.InceptionV3\nelif selectedModel == \"resnet50\":\n    imgsz = 224; ## 224 resnet and vgg, 299 for inception\n    from tensorflow.keras.applications.resnet50 import preprocess_input\n    sourceModel = keras.applications.ResNet50\n\n    \n    \n\nmodelName = \"model_\" + selectedModel + \".model\";\n\n\ntestmodel = tf.keras.models.load_model(\n    modelName)\n#    custom_objects=None,\n#    compile=True\n#)\n\nf = open(\"label_\" + selectedModel + \".sav\",'rb');labels = pickle.load(f);f.close();\nlabels = list(labels.values());\n\nX = [];\ny = [];\n\n\nidx = random.randint(0,len(labels)-1)\nlabel = labels[idx]\n\nimgFiles = []\nfor ctrext in range(0,len(ext)):\n    imgFiles.extend(glob.glob(dataPath[:-1] + \"test\" + \"/\" + label + \"/*\" + ext[ctrext]))\n\nidxFile = random.randint(0,len(imgFiles)-1)\n\nfilepath = imgFiles[idxFile]\npos1 = filepath.find(\"/\")\npos2 = filepath.find(\"/\",pos1+1)\nactualClass = filepath[pos1+1:pos2]\n\n## CV IMAGE LOAD\nimg = cv.imread(filepath);\nimg = cv.cvtColor(img,cv.COLOR_BGR2RGB);\n\n\nplt.title(\"Input Image\")\nplt.imshow(img)\nplt.show()\n\nimg = cv.resize(img,(imgsz,imgsz));\nimg = preprocess_input(img);\n\ny_pred = testmodel.predict(np.array([img]));\nprint(\"Image Classified as: \",labels[np.argmax(y_pred[0])])\nprint(\"Actual Class:\",actualClass)\nprint(\"Classification Score: \",max(y_pred[0]))","metadata":{"id":"_3sCkVv-WCni","papermill":{"duration":10.396742,"end_time":"2021-11-23T04:33:13.768698","exception":false,"start_time":"2021-11-23T04:33:03.371956","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}